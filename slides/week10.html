---
layout: slide
title: "Uge 10 - HTML"
solutions: "show"
---

<section>
	<p>Program for i dag</p>
	<ul style="font-size: smaller;">
		<li>Vi skal lave øvelser med
			<ul style="font-size: smaller;">
				<li>HTML</li>
			</ul>
		</li>
		<li>Simpel "web scraping" i python
			<ul>
				<li>bs4 - BeautifulSoup</li>
				<li>Wikipedia-artikler for truede sprog (Unesco dataset)</li>
			</ul>
		</li>
	</ul>
	</p>
</section>

<section>
	<p>bs4 - BeautifulSoup</p>
	<figure>
		<img src="https://cdn-images-1.medium.com/max/495/1*AaAIETIq7XNlLrFQW7BtZg.png">
		<figcaption><p style="font-size: 9pt">Billede: <a href=https://medium.com/@shivangisareen/beautiful-soup-in-python-79697b33e294>https://medium.com/@shivangisareen/beautiful-soup-in-python-79697b33e294</a></p></figcaption>
	</figure>
</section>

<section>
	<p>bs4 - BeautifulSoup</p>
	<ul style="font-size: smaller;">
		<li>Modul (kan installeres vha. pip)</li>
		<li>Parse/læse html-sider</li>
		<li>Alternativ til at arbejde med html-sider som strenge</li>
		<li>Læser strukturen på html-siden</li>
	</ul>
</section>

<section>
	<p>bs4 - BeautifulSoup</p>

		<pre style="font-size: medium;"><code data-trim class="python">
			# Import BeautifulSoup
			from bs4 import BeautifulSoup

			# Html string
			html = """
				<div>
					<h2>Mine slides for i dag</h2>
					<p> I dag skal vi arbejde med</p>
					<ul>
						<li>Lister</li>
						<li>Strings</li>				
						<li>Sets</li>
						<li>Dictionaries <em>fortsat fra sidste gang</em></li>
					</ul>
				</div> 
			"""

			# Parse html string uisng beautifulsoup
			soup = BeautifulSoup(html, "lxml")

			# Get all of the list items
			to_do = soup.find_all("li")

			# Enumerate through the list items
			for i, item in enumerate(to_do):
				print(i, item.get_text()) # Print cleaned text
		</code></pre>
</section>



<section style="font-size: smaller;">
	<p>Opgave 1: Wiki-beskrivelser af de truede sprog</p>
	<ul style="font-size: smaller;">
		<li>Liste over truede sprog, <icode>endangered_europe.csv</icode>, på absalon</li>	
	</ul>
		<pre><code data-trim data-noescape class="text" style="font-size: smaller;">
			ID;Name in English;Name in French;Name in Spanish;Countries;Degree of endangerment;Number of speakers
			382;Lombard;lombard;lombardo;Italy, Switzerland;Definitely endangered;3500000
			1022;South Italian;italien du sud;napolitano-calabrés;Italy;Vulnerable;7500000
			1023;Sicilian;sicilien;siciliano;Italy;Vulnerable;5000000
		</code></pre>	

		<pre><code data-trim data-noescape class="text" style="font-size: smaller;">
			ID;	 Name in English; Name in French; Name in Spanish;     Countries;		   Degree of endangerment; Number of speakers
			382; Lombard;		  lombard;		  lombardo;		       Italy, Switzerland; Definitely endangered;   3500000
			1022;South Italian;	  italien du sud; napolitano-calabrés; Italy;              Vulnerable;              7500000
			1023;Sicilian;        sicilien;	      siciliano;	       Italy;			   Vulnerable;			    5000000
		</code></pre>	
</section>

<section style="font-size: smaller;">
	<p>Opgave 1: Wiki-beskrivelser af de truede sprog</p>
	<ul style="font-size: smaller;">
		<li>Wikipedia-artikel <a href="https://en.wikipedia.org/wiki/Sicilian_language">https://en.wikipedia.org/wiki/Sicilian_language</a></li>
		<img src="wikiSicilian_language.png">
	</ul>
</section>



<section style="font-size: smaller;">
	<p>Opgave 1: Wiki-beskrivelser af de truede sprog</p>
	<ol style="font-size: smaller;">
		<li>Indlæs <icode>endangered_europe.csv</icode> i python</li>
		<li> For hver af sprogene sprogene skal i generere en URL-streng som svarer til sprogets wikipedia-artikel:
			<ul>
				<li>Hvis sprogets engelsk navn er "Sicilian": <icode>https://en.wikipedia.org/wiki/<mark>Sicilian</mark>_language</icode></li>
				<li>Hvis sprogets engelsk navn er "South Italian": <icode>https://en.wikipedia.org/wiki/<mark>South_Italian</mark>_language</icode></li>
				<li>Dette virker for de fleste sprog, men ikke alle</li>
				<li>Hvis I kan (brug ikke for meget tid på det), så fjern eventuelt parenteser fra navnene</li>
			</ul>
		</li>
	</ol>
</section>

<section style="font-size: smaller;" class="solution">
		<p>1-2 (løsning)</p>
		<pre><code data-trim data-noescape class="python">

		def generateWikiURL(entry, postfix="", lang="en"):
			# Url separator
			sep="_"

			# Base url
			base = "https://{l}.wikipedia.org/wiki/{e}"

			# Search terms
			entry = entry.split()
			postfix = postfix.split()

			url = base.format(l=lang, e=sep.join(entry))

			if postfix: url += sep+sep.join(postfix)

			return url

		urls = []
		path = "data/endangered_europe.csv"
		sep = ";"

		f = open(path, "r")
		f.readline()

		for line in f:
			line = line.strip()

			values = line.split(sep)
			language_en = values[1]

			# Remove parentheses
			parindex = language_en.find("(")

			if parindex!=-1:
				language_en = language_en[:parindex].strip()
			
			url = generateWikiURL(language_en, postfix="language")
			print(language_en, url)
			urls.append(url)
		f.close()	

		</code></pre>
</section>

<section style="font-size: smaller;">
	<p>Opgave 1: Wiki-beskrivelser af de truede sprog</p>
	<ol style="font-size: smaller;" start=3>
		<li>Brug <icode>urllib</icode> til at indlæse hver af sprogenes wikipedia-artikler i python
			<pre><code data-trim data-noescape class="python" style="font-size: smaller;">
				import urllib

				def requestURL(url):
					try:
						return urllib.request.urlopen(url)
					except urllib.error.HTTPError:
						return "No site found"
					except UnicodeEncodeError:
						return "Could not read url"
		</code></pre>	
		</li>
		<li>Brug <icode>BeautifulSoup</icode> til at finde artiklernes første to paragraffer (indholdet af de to første <icode class="html">&lt;p&gt;</icode> tags)</li>
		<li>Print beskrivelserne af sprogene i python</li>
	<ol>
</section>


<section style="font-size: smaller;" class="solution">
		<p>3-5 (løsning)</p>
		<pre><code data-trim data-noescape class="python">
			for url in urls:
				html = requestURL(url)
				soup = BeautifulSoup(html, "lxml")

				paragraphs = soup.find_all("p")

				# Get first non-empty paragraph
				i = 0
				while not paragraphs[i].get_text().strip() and i < len(paragraphs)-1:
					i+=1
				
				print(language_en, url)
				print(paragraphs[i].get_text())
				print()
		</code></pre>
</section>


<section style="font-size: smaller;">
	<p>(bonus) Opgave 2: Hjemmeside om truede sprog</p>
	<ol style="font-size: smaller;">
		<li> Hvis I når så langt, så prøv at skrive en html-fil i python, hvor I bruger dataen fra csv-filen sammen med de scrapede wiki-artikler
		</li>
		<li> Det kunne for eksempel være i en tabel eller som ren tekst med overskrifter
		</li>
	<ol>
</section>